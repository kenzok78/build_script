From 59c67beb45a1d4d4684d06400b90109bbdb6320e Mon Sep 17 00:00:00 2001
From: Neal Cardwell <ncardwell@google.com>
Date: Wed, 29 Aug 2018 10:27:59 -0400
Subject: [PATCH 17/27] net-test: scripts for testing bbr2 with upstream Linux
 kernels

- runs a small set of simple tests
  - sets up netem to emulate a configured network scenario
  - runs /usr/bin/netperf and /usr/bin/netserver to generate traffic
  - writes pcaps and ss logs
- analyzes test results
- generates graphs

Usage:
  ./run_tests.sh
  ./graph_tests.sh

Effort: net-test
Change-Id: I38662f554b3c905aa79947a2c52a2ecfe3943f8c
---
 gtests/net/tcp/bbr/nsperf/graph_tests.sh   | 306 ++++++++++++
 gtests/net/tcp/bbr/nsperf/median.py        |  43 ++
 gtests/net/tcp/bbr/nsperf/nsperf.py        | 540 +++++++++++++++++++++
 gtests/net/tcp/bbr/nsperf/run_tests.sh     | 201 ++++++++
 gtests/net/tcp/bbr/nsperf/ss_log_parser.py | 193 ++++++++
 5 files changed, 1283 insertions(+)
 create mode 100755 gtests/net/tcp/bbr/nsperf/graph_tests.sh
 create mode 100755 gtests/net/tcp/bbr/nsperf/median.py
 create mode 100755 gtests/net/tcp/bbr/nsperf/nsperf.py
 create mode 100755 gtests/net/tcp/bbr/nsperf/run_tests.sh
 create mode 100755 gtests/net/tcp/bbr/nsperf/ss_log_parser.py

diff --git a/gtests/net/tcp/bbr/nsperf/graph_tests.sh b/gtests/net/tcp/bbr/nsperf/graph_tests.sh
new file mode 100755
index 000000000000..6277c4ffa1cc
--- /dev/null
+++ b/gtests/net/tcp/bbr/nsperf/graph_tests.sh
@@ -0,0 +1,306 @@
+#!/bin/bash
+# For all test results, generate png graphs and an HTML page linking to them.
+#
+# By default, graphs all tests:
+#   ./graph_tests.sh
+# But you can also graph a subset of tests by setting the "tests"
+# environment variable:
+#   tests="coexist shallow" ./graph_tests.sh
+#
+# fancier usage:
+#          indir=out.180.sec/ outdir=graphs/ ./graph_tests.sh
+
+if [ "$indir" = "" ]; then
+    indir="out/"
+fi
+
+if [ "$outdir" = "" ]; then
+    outdir="graphs/"
+fi
+
+# By default graph all tests.
+# To graph a subset of tests, set the environment variable: tests="foo bar".
+if [ "$tests" = "" ]; then
+    tests="coexist random_loss shallow bufferbloat ecn_bulk"
+fi
+
+format=png
+if [ "$format" = "png" ]; then
+  PNG_SIZE="1024,768"
+  TERMINAL="set terminal pngcairo noenhanced size $PNG_SIZE"
+else
+  TERMINAL="set terminal wxt noenhanced size 1024,768"
+fi
+
+mkdir -p $outdir
+
+# Start HTML for a web page showing all png graphs we generate.
+TITLE="bbr v2 alpha upstream core tests"
+HTML_PATH="${outdir}/index.html"
+echo > $HTML_PATH
+echo "<html><title>$TITLE</title><body> <b> $TITLE </b> <br>\n" >> $HTML_PATH
+
+if [[ $tests == *"coexist"* ]]; then
+    #######
+    # show acceptable coexistence w/ cubic:
+    # graph tput of 1 cubic, 1 BBR at a range of buffer depths:
+    # (bw=50M, rtt=30ms, buf={...}xBDP)
+    rm -f $outdir/coexist.*
+    for cc_combo in cubic:1,bbr:1 cubic:1,bbr2:1; do
+	for bdp_of_buf in  0.1  1 2 4 8 16; do
+	    echo -n "$bdp_of_buf " >> $outdir/coexist.${cc_combo}
+	    grep THROUGHPUT $indir/coexist/${cc_combo}/${bdp_of_buf}/netperf.out.1.txt | \
+		cut -d= -f2 >> $outdir/coexist.${cc_combo}
+	done
+    done
+
+    OUTPNG="$outdir/coexist_1xcubic_1xbbr2_50M_30ms_varybuf.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top left\n\
+	set ytics nomirror\n\
+	set grid\n\
+	set title  'cubic vs BBR throughput'\n\
+        set xlabel 'buffer size (as a multiple of BDP)'\n\
+        set ylabel 'throughput in Mbit/sec'\n\
+	set yrange [0:50]\n\
+	plot '$outdir/coexist.cubic:1,bbr:1'  u 1:2 t 'bbr'  w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/coexist.cubic:1,bbr2:1' u 1:2 t 'bbr2' w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/coexist.gnuplot
+
+    gnuplot -persist $outdir/coexist.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+fi
+
+
+if [[ $tests == *"random_loss"* ]]; then
+    #######
+    # show high throughput with random loss up to design parameter:
+    # graph tput of cubic, bbr2 at a range of random loss rates
+    # (bw=1G, rtt=100ms, loss={...}
+    rm -f $outdir/random_loss.*
+    loss_rates="0.00001 0.0001 0.001 0.01 0.1 0.2 0.5 1 2 3 10 15 20"
+    for loss_rate in $loss_rates; do
+	for cc_name in cubic bbr bbr2; do
+	    cc="${cc_name}:1"
+	    sumd="$indir/random_loss/${cc}/${loss_rate}/summary/"
+	    mkdir -p $sumd
+	    rm -f "${sumd}/*txt"
+	    for rep in `seq 1 10`; do
+		d="$indir/random_loss/${cc}/${loss_rate}/rep-${rep}"
+		grep THROUGHPUT ${d}/netperf.out.0.txt | cut -d= -f2 >> ${sumd}/THROUGHPUT.samples.txt
+	    done
+	    infile="${sumd}/THROUGHPUT.samples.txt" ./median.py > \
+		  ${sumd}/THROUGHPUT.median.txt
+	    echo -n "$loss_rate " >> $outdir/random_loss.${cc}
+	    cat ${sumd}/THROUGHPUT.median.txt >> $outdir/random_loss.${cc}
+	done
+    done
+
+    OUTPNG="$outdir/random_loss_1G_100ms_varyloss.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top right\n\
+	set ytics nomirror\n\
+	set grid\n\
+        set logscale x\n\
+	set title  'cubic, bbr, and bbr2 throughput with random loss'\n\
+        set xlabel 'random loss rate, in percent'\n\
+        set ylabel 'throughput in Mbit/sec'\n\
+	set yrange [0:1000]\n\
+        set xrange [:20]\n\
+	plot '$outdir/random_loss.cubic:1' u 1:2 t 'cubic' w lp lw 2 pt 7 lt rgb \"#d7191c\",\
+	     '$outdir/random_loss.bbr:1'   u 1:2 t 'bbr' w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/random_loss.bbr2:1'  u 1:2 t 'bbr2'  w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/random_loss.gnuplot
+
+    gnuplot -persist $outdir/random_loss.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+fi
+
+
+if [[ $tests == *"shallow"* ]]; then
+    #######
+    # show reasonably low loss rates in shallow buffers:
+    # graph retransmit rate for range of flow counts
+    # (bw=1G, rtt=100ms, buf=1ms, num_flows={...})
+    # BDP is 1G*100ms = 8256 packets
+    rm -f $outdir/shallow_buf.*
+    for num_flows in 1 10 30 60 100; do
+	for cc_name in cubic bbr bbr2; do
+	    echo -n "$num_flows " >> $outdir/shallow_buf.${cc_name}
+	    d="$indir/shallow/${cc_name}:${num_flows}/${num_flows}"
+	    infile=${d}/ss.log outdir=${d}/ ./ss_log_parser.py
+	    cat ${d}/retrans.out.total.txt >> $outdir/shallow_buf.${cc_name}
+	done
+    done
+
+    OUTPNG="$outdir/shallow_buf_1G_100ms_varynumflows.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top left\n\
+	set ytics nomirror\n\
+	set grid\n\
+        set logscale x\n\
+	set title  'cubic, bbr, and bbr2 retransmit rate in shallow buffers'\n\
+        set xlabel 'number of flows'\n\
+        set ylabel 'retransmit rate (percent)'\n\
+	set yrange [0:15]\n\
+        set xrange [:]\n\
+	plot '$outdir/shallow_buf.cubic' u 1:2 t 'cubic' w lp lw 2 pt 7 lt rgb \"#d7191c\",\
+	     '$outdir/shallow_buf.bbr'   u 1:2 t 'bbr' w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/shallow_buf.bbr2'  u 1:2 t 'bbr2'  w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/shallow_buf.gnuplot
+
+    gnuplot -persist $outdir/shallow_buf.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+fi
+
+
+if [[ $tests == *"bufferbloat"* ]]; then
+    #######
+    # show low delay in deep buffers, even without ECN signal:
+    # graph p50 RTT for two flows using either cubic or bbr2,
+    # at a range of buffer depths.
+    # (bw=50M, rtt=30ms, buf={...}xBDP)
+    rm -f $outdir/bufferbloat.*
+    for bdp_of_buf in 1 10 50 100; do
+	for cc_name in cubic bbr bbr2; do
+	    echo -n "$bdp_of_buf " >> $outdir/bufferbloat.${cc_name}
+	    num_flows=2
+	    d="$indir/bufferbloat/${cc_name}:${num_flows}/${bdp_of_buf}"
+	    infile=${d}/ss.log outdir=${d}/ ./ss_log_parser.py
+	    cat ${d}/rtt_p50.out.total.txt >> $outdir/bufferbloat.${cc_name}
+	done
+    done
+
+    OUTPNG="$outdir/bufferbloat_50M_30ms_varybuf.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top left\n\
+	set ytics nomirror\n\
+	set grid\n\
+	set title  'cubic, bbr, and bbr2 median RTT'\n\
+        set xlabel 'buffer size (as a multiple of BDP)'\n\
+        set ylabel 'median srtt sample (ms)'\n\
+	set yrange [0:]\n\
+        set xrange [1:100]\n\
+	plot '$outdir/bufferbloat.cubic' u 1:2 t 'cubic' w lp lw 2 pt 7 lt rgb \"#d7191c\",\
+	     '$outdir/bufferbloat.bbr'   u 1:2 t 'bbr' w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/bufferbloat.bbr2'  u 1:2 t 'bbr2'  w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/bufferbloat.gnuplot
+
+    gnuplot -persist $outdir/bufferbloat.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+fi
+
+if [[ $tests == *"ecn_bulk"* ]]; then
+    rm -f $outdir/ecn_bulk.*
+
+    #######
+    # show ECN support can keep queues very low:
+    # graph p50 for range of flow counts.
+    # (bw=1G, rtt=1ms, num_flows={...})
+    # For each CC and flow count, show the median of the p50 RTT from N trials.
+    for cc_name in dctcp bbr2 bbr; do
+	for num_flows in 1 4 10 40 100; do
+	    sumd="$indir/ecn_bulk/${cc_name}/${num_flows}/summary/"
+	    mkdir -p $sumd
+	    rm -f "${sumd}/*txt"
+	    for rep in `seq 1 10`; do
+		# Find median srtt for this rep, and add it to list
+		# of all samples.
+		d="$indir/ecn_bulk/${cc_name}/${num_flows}/rep-${rep}"
+		infile=${d}/ss.log outdir=${d}/ ./ss_log_parser.py
+		cat ${d}/rtt_p50.out.total.txt >> ${sumd}/rtt_p50.out.samples.txt
+	    done
+	    infile="${sumd}/rtt_p50.out.samples.txt" ./median.py > \
+		  ${sumd}/rtt_p50.out.median.txt
+	    echo -n "$num_flows " >> $outdir/ecn_bulk.${cc_name}
+	    cat ${sumd}/rtt_p50.out.median.txt >> $outdir/ecn_bulk.${cc_name}
+	done
+    done
+
+    OUTPNG="$outdir/ecn_bulk_1G_1ms_rtt_varynumflows.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top left\n\
+	set ytics nomirror\n\
+	set grid\n\
+        set logscale x\n\
+	set title  'dctcp, bbr, and bbr2 median RTT'\n\
+        set xlabel 'number of flows'\n\
+        set ylabel 'median srtt sample (ms)'\n\
+	set yrange [0:]\n\
+        set xrange [1:100]\n\
+	plot '$outdir/ecn_bulk.dctcp'       u 1:2 t 'dctcp'           w lp lw 2 pt 7 lt rgb \"#d7191c\",\
+	     '$outdir/ecn_bulk.bbr'         u 1:2 t 'bbr'             w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/ecn_bulk.bbr2'  u 1:2 t 'bbr2' w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/ecn_bulk_rtt.gnuplot
+
+    gnuplot -persist $outdir/ecn_bulk_rtt.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+
+
+    #######
+    # show ECN support can keep queues very low:
+    # graph median of retrans rates across N trials:
+    for cc_name in dctcp bbr2 bbr; do
+	for num_flows in 1 4 10 40 100; do
+	    sumd="$indir/ecn_bulk/${cc_name}/${num_flows}/summary/"
+	    mkdir -p $sumd
+	    rm -f "${sumd}/*txt"
+	    for rep in `seq 1 10`; do
+		# Find overall retrans rate for this rep, and add it to list
+		# of all samples.
+		d="$indir/ecn_bulk/${cc_name}/${num_flows}/rep-${rep}"
+		cat ${d}/retrans.out.total.txt >> ${sumd}/retrans.out.samples.txt
+	    done
+	    infile="${sumd}/retrans.out.samples.txt" ./median.py > \
+		  ${sumd}/retrans.out.median.txt
+	    echo -n "$num_flows " >> $outdir/ecn_bulk.retrans.${cc_name}
+	    cat ${sumd}/retrans.out.median.txt >> $outdir/ecn_bulk.retrans.${cc_name}
+	done
+    done
+
+    OUTPNG="$outdir/ecn_bulk_1G_1ms_retrans_varynumflows.png"
+    OUTPUT="\n\
+set output '$OUTPNG'"
+
+    echo -e "set y2tics\n\
+	$TERMINAL $OUTPUT\n\
+	set key top left\n\
+	set grid\n\
+        set logscale x\n\
+        set logscale y\n\
+	set title  'dctcp, bbr, and bbr2 retransmit rate'\n\
+        set xlabel 'number of flows'\n\
+        set ylabel 'retransmit rate (percent)'\n\
+	set yrange [:]\n\
+        set xrange [1:100]\n\
+	plot '$outdir/ecn_bulk.retrans.dctcp'       u 1:2 t 'dctcp' axis x1y1 w lp lw 2 pt 7 lt rgb \"#d7191c\",\
+	     '$outdir/ecn_bulk.retrans.bbr'         u 1:2 t 'bbr'   axis x1y1 w lp lw 2 pt 7 lt rgb \"#abd9e9\",\
+	     '$outdir/ecn_bulk.retrans.bbr2'  u 1:2 t 'bbr2'  axis x1y1 w lp lw 2 pt 7 lt rgb \"#2c7bb6\"\
+             \n" > $outdir/ecn_bulk_retrans.gnuplot
+
+    gnuplot -persist $outdir/ecn_bulk_retrans.gnuplot
+    echo -e "<img src='$OUTPNG'>\n" >> $HTML_PATH
+
+fi
+
+echo "done graphing all tests: $tests"
diff --git a/gtests/net/tcp/bbr/nsperf/median.py b/gtests/net/tcp/bbr/nsperf/median.py
new file mode 100755
index 000000000000..f09ae072e0fd
--- /dev/null
+++ b/gtests/net/tcp/bbr/nsperf/median.py
@@ -0,0 +1,43 @@
+#!/usr/bin/python
+#
+# Read a file with one float per line, and print the median of all numbers.
+# Usage:
+#    infile=numbers.txt ./median.py
+
+import os
+import sys
+
+def read_file():
+    """Read a file with one float per line, and return as a list of floats."""
+
+    nums = []
+
+    path = os.environ['infile']
+    f = open(path)
+
+    # Read a line, or EOF.
+    line = f.readline()
+    while True:
+        if not line:
+            return nums
+        num_str = line.strip()
+        num = float(num_str)
+        nums.append(num)
+        line = f.readline()
+
+def median(nums):
+    """Return median of all numbers."""
+
+    sorted_nums = sorted(nums)
+    n = len(sorted_nums)
+    m = n - 1
+    return (sorted_nums[n/2] + sorted_nums[m/2]) / 2.0
+
+def main():
+    """Main function to run everything."""
+    nums = read_file()
+    print('%s' % median(nums))
+    return 0
+
+if __name__ == '__main__':
+    sys.exit(main())
diff --git a/gtests/net/tcp/bbr/nsperf/nsperf.py b/gtests/net/tcp/bbr/nsperf/nsperf.py
new file mode 100755
index 000000000000..c8b5f697f0a8
--- /dev/null
+++ b/gtests/net/tcp/bbr/nsperf/nsperf.py
@@ -0,0 +1,540 @@
+#!/usr/bin/python
+#
+# Use netem, network namespaces, and veth virtual NICs
+# to run a multi-flow TCP test on a single Linux machine.
+#
+# There is one network namespace for each emulated host.
+# The emulated hosts are as follows:
+#
+#   srv: server (sender)
+#   srt: server router
+#   mid: middle host to emulate delays and bandwidth constraints
+#   crt: client router
+#   cli: client (receiver)
+#
+# Most hosts have both a left ("l") and right ("r") virtual NIC.
+# The server has only an "r" NIC and the client has only an "l" NIC.
+#
+# The topology is as follows:
+#
+#   +-------+ +-------+ +-------+ +-------+ +-------+
+#   |  srv  | |  srt  | |  mid  | |  crt  | |  cli  |
+#   |     r +-+ l   r +-+ l   r +-+ l   r +-+ l     |
+#   +-------+ +-------+ +-------+ +-------+ +-------+
+#
+# Authors:
+#  Neal Cardwell
+#  Soheil Hassas Yeganeh
+#  Kevin (Yudong) Yang
+#  Arjun Roy
+
+import os
+import os.path
+import socket
+import sys
+import threading
+import time
+
+HOSTS = ['cli', 'crt', 'mid', 'srt', 'srv']
+IP_MODE = socket.AF_INET6
+SS_INTERVAL_SECONDS = 0.1  # gather 'ss' stats each X seconds
+FIRST_PORT = 10000         # first TCP port to use
+
+# On Ubuntu 18.04.2 LTS, there are issues with the iproute2 binaries:
+#  (1) the 'tc' binary  has a bug and cannot parse netem random loss rates
+#  (2) the 'ss' tool is missing recent socket stats
+# So to use this testing tool you may need to build your own iproute2 tools
+# from the latest iproute2 sources:
+#   sudo su -
+#   apt install pkg-config bison flex
+#   mkdir -p /root/iproute2/
+#   cd /root/iproute2
+#   git clone git://git.kernel.org/pub/scm/network/iproute2/iproute2.git
+#   cd iproute2/
+#   ./configure
+#   make
+SS_PATH = '/root/iproute2/iproute2/misc/ss'
+TC_PATH = '/root/iproute2/iproute2/tc/tc'
+
+def netperf():
+    if os.path.isfile('./netperf'):
+        return './netperf'
+    else:
+        return '/usr/bin/netperf'
+
+def netserver():
+    if os.path.isfile('./netserver'):
+        return './netserver'
+    else:
+        return '/usr/bin/netserver'
+
+def log_dir():
+    return '/tmp/'
+
+def run(cmd, verbose=True):
+    if verbose:
+        print('running: |%s|' % (cmd))
+    status = os.system(cmd)
+    if status != 0:
+        sys.stderr.write('error %d executing: %s' % (status, cmd))
+
+def cleanup():
+    """Delete all veth pairs and all network namespaces."""
+    for host in HOSTS:
+        run('( ip netns exec %(host)s ip link del dev %(host)s.l; '
+            '  ip netns exec %(host)s ip link del dev %(host)s.r; '
+            '  ip netns del %(host)s ) 2> /dev/null'  % {'host' : host})
+
+def setup_logging():
+    """Set up all logging."""
+    # Zero out /var/log/kern-debug.log so that we only get our test logs.
+    run('logrotate -f /etc/logrotate.conf')
+    # Set up BBR to log with printk to /var/log/kern-debug.log.
+    run('echo Y > /sys/module/tcp_bbr2/parameters/debug_with_printk')
+    run('echo 3 > /sys/module/tcp_bbr2/parameters/flags')
+
+def setup_namespaces():
+    """Set up all network namespaces."""
+    for host in HOSTS:
+        run('ip netns add %(host)s'  % {'host' : host})
+
+def setup_loopback():
+    """Set up loopback devices for all namespaces."""
+    for host in HOSTS:
+        run('ip netns exec %(host)s ifconfig lo up' % {'host' : host})
+
+def setup_veth():
+    """Set up all veth interfaces."""
+    c = ''
+    c += 'ip link add srv.r type veth peer name srt.l\n'
+    c += 'ip link add srt.r type veth peer name mid.l\n'
+    c += 'ip link add mid.r type veth peer name crt.l\n'
+    c += 'ip link add crt.r type veth peer name cli.l\n'
+
+    c += 'ip link set dev srv.r netns srv\n'
+    c += 'ip link set dev srt.r netns srt\n'
+    c += 'ip link set dev srt.l netns srt\n'
+    c += 'ip link set dev mid.r netns mid\n'
+    c += 'ip link set dev mid.l netns mid\n'
+    c += 'ip link set dev crt.l netns crt\n'
+    c += 'ip link set dev crt.r netns crt\n'
+    c += 'ip link set dev cli.l netns cli\n'
+
+    c += 'ip netns exec srv ip link set srv.r up\n'
+    c += 'ip netns exec srt ip link set srt.r up\n'
+    c += 'ip netns exec srt ip link set srt.l up\n'
+    c += 'ip netns exec mid ip link set mid.r up\n'
+    c += 'ip netns exec mid ip link set mid.l up\n'
+    c += 'ip netns exec crt ip link set crt.r up\n'
+    c += 'ip netns exec crt ip link set crt.l up\n'
+    c += 'ip netns exec cli ip link set cli.l up\n'
+
+    # Disable TSO, GSO, GRO, or else netem limit is interpreted per
+    # multi-MSS skb, not per packet on the emulated wire.
+    c += 'ip netns exec srt ethtool -K srt.r tso off gso off gro off\n'
+    c += 'ip netns exec mid ethtool -K mid.l tso off gso off gro off\n'
+    c += 'ip netns exec mid ethtool -K mid.r tso off gso off gro off\n'
+    c += 'ip netns exec srt ethtool -K crt.l tso off gso off gro off\n'
+
+    # server
+    c += 'ip netns exec srv ip addr add 192.168.0.1/24 dev srv.r\n'
+
+    # server router
+    c += 'ip netns exec srt ip addr add 192.168.0.100/24 dev srt.l\n'
+    c += 'ip netns exec srt ip addr add 192.168.1.1/24   dev srt.r\n'
+
+    # mid
+    c += 'ip netns exec mid ip addr add 192.168.1.100/24 dev mid.l\n'
+    c += 'ip netns exec mid ip addr add 192.168.2.1/24   dev mid.r\n'
+
+    # client router
+    c += 'ip netns exec crt ip addr add 192.168.2.100/24 dev crt.l\n'
+    c += 'ip netns exec crt ip addr add 192.168.3.1/24   dev crt.r\n'
+
+    # client
+    c += 'ip netns exec cli ip addr add 192.168.3.100/24 dev cli.l\n'
+
+    run(c)
+
+def setup_routes():
+    """Set up all routes."""
+    c = ''
+
+    # server
+    c += 'h=srv\n'
+    c += 'ip netns exec $h tc qdisc add dev $h.r root fq\n'
+    c += 'ip netns exec $h ip route add default via 192.168.0.100 dev $h.r\n'
+
+    # server router
+    c += 'h=srt\n'
+    c += 'ip netns exec $h ip route add default via 192.168.1.100 dev $h.r\n'
+
+    # mid
+    c += 'h=mid\n'
+    c += 'ip netns exec $h ip route add 192.168.3.0/24 via 192.168.2.100\n'
+    c += 'ip netns exec $h ip route add default via 192.168.1.1 dev $h.l\n'
+
+    # client router
+    c += 'h=crt\n'
+    c += 'ip netns exec $h ip route add default via 192.168.2.1 dev $h.l\n'
+
+    # cli
+    c += 'h=cli\n'
+    c += 'ip netns exec $h ip route add default via 192.168.3.1 dev $h.l\n'
+
+    run(c)
+
+def setup_forwarding():
+    """Enable forwarding in each namespace."""
+    for host in HOSTS:
+        run('ip netns exec %(host)s sysctl -q -w '
+            'net.ipv4.ip_forward=1 '
+            'net.ipv6.conf.all.forwarding=1'  % {'host' : host})
+
+def netem_limit(rate, delay, buf):
+    """Get netem limit in packets.
+
+    Needs to hold the packets in emulated pipe and emulated buffer.
+    """
+    bdp_bits = (rate * 1000000.0) * (delay / 1000.0)
+    bdp_bytes = bdp_bits / 8.0
+    bdp = int(bdp_bytes / 1500.0)
+    limit = bdp + buf
+    return limit
+
+# Parse string like 'cubic:1,bbr:2' and return an array like:
+# ['cubic', 'bbr', 'bbr']
+def parse_cc_param(param_string):
+    cc_list = []
+    groups = param_string.split(',')
+    for group in groups:
+        (cc_name, count) = group.split(':')
+        count = int(count)
+        for i in range(0, count):
+            cc_list.append(cc_name)
+    return cc_list
+
+def get_params():
+    # Invocations of this tool should set the following parameters as
+    # environment variables.
+    params = {
+        'bw':          -1, # input bottleneck bw in Mbit/sec; required
+        'rtt':         -1, # RTT in ms; required
+        'buf':         -1, # input bottleneck buffer in packets; required
+        'loss':         0, # input bottleneck loss rate in percent; optional
+        'policer':      0, # input bottleneck policer rate, Mbit/sec; optional
+        'cc':          '', # congestion control algorithm: required
+        'interval':     0, # interval between flow starts, in secs; optional
+        'dur':         -1, # length of test in secs: required
+        'outdir':      '', # output directory for results
+        'qdisc':       '', # qdisc at downstream bottleneck (empty for FIFO)
+        'cmd':         '', # command to run (e.g. set sysctl values)
+        'pcap':         0, # bytes per packet to capture; 0 for no tracing
+    }
+
+    for key in params.keys():
+        print('parsing key %s' % key)
+        if key in os.environ:
+           print('looking at env var with key %s, val %s' % (key, os.environ[key]))
+        else:
+           print('no env var with key %s' % (key))
+        if key not in os.environ:
+            if params[key] != 0:
+              sys.stderr.write('missing %s in environment variables\n' % key)
+              sys.exit(1)
+        elif key == 'cc':
+            params[key] = parse_cc_param(os.environ[key])
+        elif type(params[key]) == str:
+            params[key] = os.environ[key]
+        else:
+            params[key] = float(os.environ[key])
+
+    print(params)
+    params['netperf'] = netperf()
+    params['receiver_ip'] = '192.168.3.100'
+    # 10Gbit/sec * 100ms is 125MBytes, so to tolerate
+    # high loss rates and lots of SACKed data, we use
+    # 512MByte socket send and receive buffers:
+    params['mem'] = 536870912
+    return params
+
+# Put bandwidth rate limiting using HTB, tied to user-specified
+# queuing discipline at that bottleneck, on traffic coming in the cli.l device.
+def setup_htb_and_qdisc(d):
+    """Set up HTB for rate limiting, and user-specified qdisc for the queue."""
+
+    c = ''
+
+    # First load the necessary modules.
+    c += ('rmmod ifb\n'
+          'modprobe ifb numifbs=10\n'
+          'modprobe act_mirred\n')
+
+    # Clear old queuing disciplines (qdisc) on the interfaces
+    d['ext']         = 'cli.l'
+    d['ext_ingress'] = 'cli.ifb0'
+    d['host'] = 'cli'
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc del dev %(ext)s root\n') % d
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc del dev %(ext)s ingress\n') % d
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc del dev %(ext_ingress)s root\n') % d
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc del dev %(ext_ingress)s ingress\n') % d
+
+    # Create ingress ifb0 on client interface.
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc add dev %(ext)s handle ffff: ingress\n') % d
+    c += ('ip netns exec %(host)s '
+          'ip link add %(ext_ingress)s type ifb\n') % d
+    c += ('ip netns exec %(host)s '
+          'ip link set dev %(ext_ingress)s up\n') % d
+    c += ('ip netns exec %(host)s '
+          'ifconfig %(ext_ingress)s txqueuelen 128000\n') % d
+    c += ('ip netns exec %(host)s '
+          'ifconfig %(ext_ingress)s\n') % d
+
+    # Forward all ingress traffic to the IFB device.
+    c += ('ip netns exec %(host)s '
+          '%(tc)s filter add dev %(ext)s parent ffff: protocol all u32 '
+          'match u32 0 0 action mirred egress redirect '
+          'dev %(ext_ingress)s\n') % d
+
+    # Create an egress filter on the IFB device.
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc add dev %(ext_ingress)s root handle 1: '
+          'htb default 11\n') % d
+
+    # Add root class HTB with rate limiting.
+    c += ('ip netns exec %(host)s '
+          '%(tc)s class add dev %(ext_ingress)s parent 1: classid 1:11 '
+          '  htb rate %(IRATE)sMbit ceil %(IRATE)sMbit\n') % d
+
+    # Add qdisc for downstream bottleneck.
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc add dev %(ext_ingress)s parent 1:11 handle 20: '
+          '%(QDISC)s\n') % d
+
+    c += ('ip netns exec %(host)s %(tc)s -stat qdisc show\n') % d
+
+    return c
+
+def setup_netem(params):
+    """Set up netem on the crt (client router) host."""
+
+    d = {}
+
+    # Parameters for data direction.
+    d['IRATE']   = params['bw']      # Mbit/sec
+    d['IDELAY']  = params['rtt'] / 2 # ms
+    d['IBUF']    = params['buf']     # packets
+    d['ILOSS']   = params['loss']
+    d['IREO']    = 0  # TODO: not implemented yet
+    d['ILIMIT'] = netem_limit(rate=d['IRATE'], delay=d['IDELAY'], buf=d['IBUF'])
+    d['POLICER'] = params['policer'] # Mbit/sec
+    d['QDISC']   = params['qdisc']
+
+    # Parameters for ACK direction.
+    d['ORATE']  = 1000 # Mbit/sec; TODO: not implemented yet
+    d['ODELAY'] = params['rtt'] / 2 # ms
+    d['OBUF']   = 1000 # packets; TODO: not implemented yet
+    d['OLOSS']  = 0  # TODO: not implemented yet
+    d['OREO']   = 0  # TODO: not implemented yet
+    d['OLIMIT'] = netem_limit(rate=d['ORATE'], delay=d['ODELAY'], buf=d['OBUF'])
+
+    d['tc'] = TC_PATH
+
+    c = ''
+
+    # TODO: fix the policer mechanism to actually work...
+    if params['policer'] > 0:
+        d['host'] = 'mid'
+        c = ('ip netns exec %(host)s '
+             '%(tc)s filter list dev  %(host)s.r\n'%
+             d)
+        run(c)
+
+        c = ('ip netns exec %(host)s '
+             '%(tc)s qdisc add dev %(host)s.l ingress\n' %
+             d)
+        run(c)
+
+        c = ('ip netns exec %(host)s '
+             '%(tc)s filter add dev %(host)s.l '
+             'parent 1: protocol ip prio 10 u32 '
+             'match ip src 192.168.0.1/32 flowid 1:2 '
+             'action police rate %(POLICER)sMbit burst 100k drop\n' %
+             d)
+        run(c)
+        c = ''
+
+    if d['QDISC'] == '':
+        # If the user doesn't need a fancy qdisc, and FIFO will do,
+        # then use netem for rate limiting and buffering,
+        # since netem seems more accurate than HTB.
+        d['INETEM_RATE'] = 'rate %(IRATE)sMbit' % d
+    else:
+        d['INETEM_RATE'] = ''
+        d['ILIMIT'] = '%d' % (2*1000*1000*1000) # buffer is in user's qdisc
+
+    # Inbound from sender -> receiver. Downstream rate limiting is on cli.l.
+    d['host'] = 'crt'
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc add dev %(host)s.r root netem '
+          'limit %(ILIMIT)s delay %(IDELAY)sms %(IREO)sms '
+          'loss random %(ILOSS)s%% %(INETEM_RATE)s\n') % d
+
+    # Outbound from receiver -> sender.
+    d['host'] = 'crt'
+    c += ('ip netns exec %(host)s '
+          '%(tc)s qdisc add dev %(host)s.l root netem '
+          'limit %(OLIMIT)s delay %(ODELAY)sms %(OREO)sms '
+          'loss random %(OLOSS)s%% '
+          'rate %(ORATE)sMbit\n') % d
+
+    c += ('ip netns exec %(host)s %(tc)s -stat qdisc show\n') % d
+
+    if (d['QDISC'] != ''):
+        c += setup_htb_and_qdisc(d)
+
+    run(c)
+
+def ss_log_thread(params):
+    """Repeatedly run ss command and append log to file."""
+    dur = params['dur']
+    outdir = params['outdir']
+    ss_log_path = os.path.join(outdir, 'ss.log')
+    receiver_ip = params['receiver_ip']
+    num_conns = len(params['cc'])
+
+    t0 = time.time()
+    t = t0
+    port_cnt = num_conns
+    f = open(ss_log_path, 'w')
+    f.truncate()
+    f.close()
+    if IP_MODE == socket.AF_INET6:
+        ss_ip = '[%s]'
+    else:
+        ss_ip = '%s'
+    ss_ip %= receiver_ip
+    ss_cmd = ('ip netns exec srv '
+              '%s -tinm "dport >= :%d and dport < :%d and dst %s" >> %s' % (
+                  SS_PATH,
+                  FIRST_PORT, FIRST_PORT + port_cnt, ss_ip, ss_log_path))
+
+    while t < t0 + dur:
+        f = open(ss_log_path, 'a')
+        f.write('# %f\n' % (time.time(),))
+        f.close()
+        run(ss_cmd, verbose=False)
+        t += SS_INTERVAL_SECONDS
+        to_sleep = t - time.time()
+        if to_sleep > 0:
+            time.sleep(to_sleep)
+
+def launch_ss(params):
+    t = threading.Thread(target=ss_log_thread, args=(params,))
+    t.start()
+    return t
+
+def run_test(params):
+    """Run one test case."""
+    print('command: %s' % (sys.argv))
+    run('uname -a; date; uptime')
+    run('grep . /sys/module/tcp_bbr2/parameters/*')
+    run('sysctl net.ipv4.tcp_ecn')
+
+    # Configure sender namespaces.
+    run('ip netns exec srv bash -c "%s"' % params['cmd'])
+
+    # Configure receiver namespace.
+    run('ip netns exec cli bash -c "%s"' % params['cmd'])
+
+    # Set up receiver process.
+    run('pkill -f netserver')
+    run('ip netns exec cli %s -N' % (netserver()))
+
+    # Set up output directory.
+    outdir = params['outdir']
+    run('mkdir -p %s' % outdir)
+
+    # Set up sender-side packet capture.
+    if params['pcap'] > 0:
+        snaplen = params['pcap']
+        path = os.path.join(outdir, 'out.pcap')
+        run('ip netns exec srv tcpdump -i srv.r -s %(snaplen)d -w %(path)s &' %
+            {'path': path, 'snaplen': snaplen})
+
+    # Set up periodic sender-side 'ss' stat capture.
+    ss_thread = launch_ss(params)
+
+    if sys.argv[1] == 'stream':
+        num_conns = len(params['cc'])
+        print('num_conns = %d' % (num_conns))
+        t0 = time.time()
+        t = t0
+        for i in range(0, num_conns):
+            conn_params = params.copy()
+            if i != num_conns - 1:
+                conn_params['bg'] = '&'  # all but the last in the background
+            else:
+                conn_params['bg'] = ''
+            conn_params['cc'] = params['cc'][i]
+            conn_params['port'] = FIRST_PORT + i
+            conn_params['outfile'] = '%s/netperf.out.%d.txt' % (outdir, i)
+            run('ip netns exec srv %(netperf)s '
+                '-l %(dur)d -H %(receiver_ip)s -- -k THROUGHPUT '
+                '-s %(mem)s,%(mem)s -S %(mem)s,%(mem)s '
+                '-K %(cc)s -P %(port)s '
+                '> %(outfile)s '
+                '%(bg)s' % conn_params)
+            t += params['interval']
+            to_sleep = t - time.time()
+            if to_sleep > 0:
+                time.sleep(to_sleep)
+    elif sys.argv[1] == 'rr':
+        params['request_size'] = (10 + 20 + 40 + 80 + 160) * 1448
+        params['test'] = sys.argv[2]
+        conn_params['port'] = FIRST_PORT
+        run('ip netns exec srv %(netperf)s '
+            ' -P 0 -t %(test)s -H %(receiver_ip)s -- '
+            '-K %(cc)s -P %(port)s '
+            '-r %(request_size)d,1 '
+            '-o P50_LATENCY,P90_LATENCY,P99_LATENCY,MAX_LATENCY,'
+            'TRANSACTION_RATE,'
+            'LOCAL_TRANSPORT_RETRANS,REMOTE_TRANSPORT_RETRANS' % params)
+    else:
+        sys.stderr.write('unknown test type argument: %s\n' % sys.argv[1])
+        sys.exit(1)
+
+    ss_thread.join()
+    run('killall tcpdump')
+
+    run('ls -l /tmp/*.gz')
+    run('cp -af /var/log/kern-debug.log ' + outdir)
+    run('rm -f ' + outdir + '/*.gz')
+    run('ls -l /tmp/*.gz')
+    run('gzip '  + outdir + '/kern-debug.log')
+    run('gzip  ' + outdir + '/out.pcap')
+    run('ls -l /tmp/*gz')
+
+def main():
+    """Main function to run everything."""
+    params = get_params()
+    cleanup()
+    setup_logging()
+    setup_namespaces()
+    setup_loopback()
+    setup_veth()
+    setup_routes()
+    setup_forwarding()
+    setup_netem(params)
+    run_test(params)
+    cleanup()
+    return 0
+
+
+if __name__ == '__main__':
+    sys.exit(main())
diff --git a/gtests/net/tcp/bbr/nsperf/run_tests.sh b/gtests/net/tcp/bbr/nsperf/run_tests.sh
new file mode 100755
index 000000000000..31fd028d1319
--- /dev/null
+++ b/gtests/net/tcp/bbr/nsperf/run_tests.sh
@@ -0,0 +1,201 @@
+#!/bin/bash
+#
+# Run a set of tests with bbr2, bbr, cubic, dctcp.
+# By default, runs all tests:
+#   ./run_tests.sh
+# But you can also run a subset of tests by setting the "tests"
+# environment variable:
+#   tests="coexist shallow" ./run_tests.sh
+#
+
+# By default run all tests.
+# To run a subset of tests, set the environment variable: tests="foo bar".
+if [ "$tests" = "" ]; then
+    tests="coexist random_loss shallow bufferbloat ecn_bulk"
+fi
+
+# Module parameters for the alpha research release of bbr2 are here:
+MOD_PARAM_DIR=/sys/module/tcp_bbr2/parameters/
+
+# Disable ECN support:
+function disable_bbr_ecn() {
+    echo 0 > $MOD_PARAM_DIR/ecn_enable
+    egrep . $MOD_PARAM_DIR/* | grep ecn_enable
+    echo 5000 > $MOD_PARAM_DIR/ecn_max_rtt_us
+    egrep . $MOD_PARAM_DIR/* | grep ecn_max_rtt_us
+}
+
+# Enable ECN support, with the understanding that all ECN signals we get
+# here will be DCTCP/L4S ECN signals:
+function enable_bbr_ecn() {
+    echo 1 > $MOD_PARAM_DIR/ecn_enable
+    egrep . $MOD_PARAM_DIR/* | grep ecn_enable
+    echo 0 > $MOD_PARAM_DIR/ecn_max_rtt_us
+    egrep . $MOD_PARAM_DIR/* | grep ecn_max_rtt_us
+}
+
+# Make sure send and receive buffers can grow quite large, e.g. for
+# bw=1G, rtt=100ms or larger.
+sysctl -w net.core.rmem_max=250000000 net.ipv4.tcp_rmem='4096 131072 250000000'
+sysctl -w net.core.wmem_max=250000000 net.ipv4.tcp_wmem='4096  16384 250000000'
+disable_bbr_ecn
+
+function get_buf_pkts() {
+    buf_pkts=`echo | awk -v bw=$bw -v rtt=$rtt -v bdp_of_buf=$bdp_of_buf '{bdp_pkts = int(bw*1000*1000*rtt/1000.0 / (1514 * 8) * bdp_of_buf); print bdp_pkts;}'`
+}
+
+if [[ $tests == *"coexist"* ]]; then
+    # show acceptable coexistence w/ cubic:
+    # graph tput of 1 cubic, 1 bbr2 at a range of buffer depths:
+    # (bw=50M, rtt=30ms, buf={...}xBDP)
+    # [run for a very long time, 10minutes, to find convergence...]
+    for cc_combo in cubic:1,bbr:1 cubic:1,bbr2:1; do
+	for bdp_of_buf in  0.1  1 2 4 8 16; do
+	    cmd=""
+	    cc=$cc_combo     # mix of CCs in this experiment
+	    interval=2       # interval between flow starts, in secs
+	    bw=50            # Mbit/sec
+	    rtt=30           # ms
+	    qdisc=''         # use netem FIFO
+	    loss=0           # loss in percent
+	    dur=180          # test duration in secs
+	    outdir="out/coexist/${cc}/$bdp_of_buf/"
+	    # Create output directory:
+	    mkdir -p $outdir
+	    get_buf_pkts
+	    set +e
+	    cc=$cc bw=$bw rtt=$rtt buf=$buf_pkts qdisc=$qdisc loss=$loss \
+	      dur=$dur cmd=$cmd outdir=$outdir interval=$interval \
+	      ./nsperf.py stream | tee ${outdir}/nsperf.out.txt
+	    set -e
+	done
+    done
+fi
+
+if [[ $tests == *"random_loss"* ]]; then
+    # show high throughput with random loss up to design parameter:
+    # graph tput of cubic, bbr2 at a range of random loss rates
+    # (bw=1G, rtt=100ms, loss={....}
+    for rep in `seq 1 10`; do
+	for cc_name in cubic bbr2 bbr; do
+	    loss_rates="0.00001 0.0001 0.001 0.01 0.1 0.2 0.5 1 2 3 10 15 20"
+	    for loss_rate in $loss_rates; do
+		cmd=""
+		cc=${cc_name}:1  # 1 flow
+		interval=0       # interval between flow starts, in secs
+		bw=1000          # Mbit/sec
+		rtt=100          # ms
+		bdp_of_buf=1     # buffer = 100% of BDP, or 100ms
+		qdisc=''         # use netem FIFO
+		loss=$loss_rate  # loss in percent
+		dur=60           # test duration in secs
+		outdir="out/random_loss/${cc}/${loss}/rep-${rep}/"
+		# Create output directory:
+		mkdir -p $outdir
+		get_buf_pkts
+		set +e
+		cc=$cc bw=$bw rtt=$rtt buf=$buf_pkts qdisc=$qdisc loss=$loss \
+		  dur=$dur cmd=$cmd outdir=$outdir interval=$interval \
+		  ./nsperf.py stream | tee ${outdir}/nsperf.out.txt
+		set -e
+	    done
+	done
+    done
+fi
+
+if [[ $tests == *"shallow"* ]]; then
+    # show reasonably low loss rates in shallow buffers:
+    # graph retransmit rate for range of flow counts
+    # (bw=1G, rtt=100ms, buf=1ms, num_flows={...})
+    # BDP is 1G*100ms = 8256 packets
+    for cc_name in cubic bbr2 bbr; do
+	for num_flows in 1 10 30 60 100; do
+	    cmd=""
+	    cc=${cc_name}:${num_flows}  # all flows bbr2
+	    interval=.139    # interval between flow starts, in secs
+	    bw=1000          # Mbit/sec
+	    rtt=100          # ms
+	    bdp_of_buf=0.02  # buffer = 2% of BDP, or 2ms
+	    qdisc=''         # use netem FIFO
+	    loss=0           # loss in percent
+	    dur=300          # test duration in secs
+	    outdir="out/shallow/${cc}/${num_flows}/"
+	    # Create output directory:
+	    mkdir -p $outdir
+	    get_buf_pkts
+	    set +e
+	    cc=$cc bw=$bw rtt=$rtt buf=$buf_pkts qdisc=$qdisc loss=$loss \
+	      dur=$dur cmd=$cmd outdir=$outdir interval=$interval \
+	      ./nsperf.py stream | tee ${outdir}/nsperf.out.txt
+	    set -e
+	done
+    done
+fi
+
+if [[ $tests == *"bufferbloat"* ]]; then
+    # show low delay in deep buffers, even without ECN signal:
+    # graph p50 RTT for two flows using either cubic or bbr2,
+    # at a range of buffer depths.
+    # (bw=50M, rtt=30ms, buf={...}xBDP)
+    for cc_name in cubic bbr2 bbr; do
+	for bdp_of_buf in 1 10 50 100; do
+	    cmd=""
+	    cc=${cc_name}:2  # 2 flows
+	    interval=2       # interval between flow starts, in secs
+	    bw=50            # Mbit/sec
+	    rtt=30           # ms
+	    qdisc=''         # use netem FIFO
+	    loss=0           # loss in percent
+	    dur=120          # test duration in secs
+	    outdir="out/bufferbloat/${cc}/${bdp_of_buf}/"
+	    # Create output directory:
+	    mkdir -p $outdir
+	    get_buf_pkts
+	    set +e
+	    cc=$cc bw=$bw rtt=$rtt buf=$buf_pkts qdisc=$qdisc loss=$loss \
+	      dur=$dur cmd=$cmd outdir=$outdir interval=$interval \
+	      ./nsperf.py stream | tee ${outdir}/nsperf.out.txt
+	    set -e
+	done
+    done
+fi
+
+
+if [[ $tests == *"ecn_bulk"* ]]; then
+    # show ECN support can keep queues very low:
+    # graph p50 and p95 RTT (and retx, tput, fairness) for range of flow counts
+    # (bw=1G, rtt=1ms, num_flows={...})
+    enable_bbr_ecn
+    for rep in `seq 1 10`; do
+	for cc_name in dctcp bbr2 bbr; do
+	    for num_flows in 1 4 10 40 100; do
+		# Inside the child/test namespaces, enable ECN for
+		# both active and passive connections:
+		cmd='sysctl net.ipv4.tcp_ecn=1'
+		cc=${cc_name}:${num_flows}  # all flows bbr2
+		interval=.005    # interval between flow starts, in secs
+		bw=1000          # Mbit/sec
+		rtt=1            # ms
+		buf_pkts=0       # not using netem buffer
+		# We set the limit to 1000 packets, or 12ms at 1Gbit/sec.
+		# We configure the target to be far higher, to disable
+		# Codel-based drops.
+		qdisc='codel ce_threshold 242us limit 1000 target 100ms'
+		loss=0           # loss in percent
+		dur=10           # test duration in secs
+		outdir="out/ecn_bulk/${cc_name}/${num_flows}/rep-${rep}/"
+		# Create output directory:
+		mkdir -p $outdir
+		get_buf_pkts
+		set +e
+		cc=$cc bw=$bw rtt=$rtt buf=$buf_pkts qdisc=$qdisc loss=$loss \
+		  dur=$dur cmd=$cmd outdir=$outdir interval=$interval \
+		  ./nsperf.py stream | tee ${outdir}/nsperf.out.txt
+		set -e
+	    done
+	done
+    done
+    disable_bbr_ecn
+fi
+
+echo "done running all tests: $tests"
diff --git a/gtests/net/tcp/bbr/nsperf/ss_log_parser.py b/gtests/net/tcp/bbr/nsperf/ss_log_parser.py
new file mode 100755
index 000000000000..3717a9fc7c23
--- /dev/null
+++ b/gtests/net/tcp/bbr/nsperf/ss_log_parser.py
@@ -0,0 +1,193 @@
+#!/usr/bin/python
+#
+# Parse ss.log textual output written by ss_log_thread() in nsperf.py.
+# Usage:
+#    infile=foo/ss.log outdir=out/ ss_log_parser.py
+#
+# Author:
+#  Neal Cardwell
+# Based on code by:
+#  Kevin (Yudong) Yang
+#  Soheil Hassas Yeganeh
+
+import os
+import socket
+import sys
+import time
+
+DEBUG = False   # enable debugging output?
+
+def debug(s):
+    if DEBUG:
+        print('DEBUG: %s' % s)
+
+def median(nums):
+    """Return median of all numbers."""
+
+    if len(nums) == 0:
+        return 0
+    sorted_nums = sorted(nums)
+    n = len(sorted_nums)
+    m = n - 1
+    return (sorted_nums[n/2] + sorted_nums[m/2]) / 2.0
+
+def read_file():
+    """Read the ss.log file and parse into a dictionary."""
+    all_data = {}   # data for all time:            <time>: time_data
+    time_data = {}  # data for the current timestamp: <port>: { field: value }
+    time_secs = -1
+    ss_log_path = os.environ['infile']
+    debug('reading path: %s' % (ss_log_path))
+    f = open(ss_log_path)
+
+    # Read a timestamp line, or per-flow tuple line, or EOF.
+    line = f.readline()
+    debug('readline 1 => %s' % (line))
+    while True:
+        debug('line => %s' % (line))
+
+        # If the file is done or data for current time is done, save time data.
+        if not line or line.startswith('# ') and len(time_data):
+            debug('all_data time %d => time_data %s' %
+                  (time_secs,  time_data))
+            all_data[time_secs] = time_data
+            time_data = {}
+
+        if not line:
+            return all_data
+
+        # Check to see if we have data for a new point in time
+        if line.startswith('# '):
+            time_secs = float(line[2:])
+            assert time_secs > 0, time_secs
+            debug('time_secs = %s' % (time_secs))
+            # Read ss column headers ("State...")
+            line = f.readline()
+            debug('readline column headers => %s' % (line))
+            # Read next line
+            line = f.readline()
+            continue
+
+        # Parse line with 4-tuple
+        debug('readline for 4-tuple => %s' % (line))
+        if not line or line.startswith('# '):
+            continue   # No live sockets with ports maching the ss query...
+        if len(line.split()) != 5:
+            sys.stderr.write('unable to find 4-tuple in: %s' % (line))
+            #print('unable to find 4-tuple in: %s' % (line))
+            sys.exit()
+        flow_data = {}
+        port = line.strip()
+        port = int(port[port.rfind(':') + 1:])
+        flow_data['port'] = port
+
+        # Read line with flow stats
+        line = f.readline()
+        debug('readline flow stats => %s' % (line))
+        assert line, 'expected flow stats for port %d' % (port)
+        stats = line.strip().split()
+        debug('stats: %s' % (stats))
+        for item in stats:
+            if item.startswith('cwnd:'):
+                flow_data['cwnd'] = int(item[item.rfind(':') + 1:])
+            elif item.startswith('bytes_acked:'):
+                flow_data['bytes_acked'] = int(item[item.rfind(':') + 1:])
+            elif item.startswith('retrans:'):
+                flow_data['retrans'] = int(item[item.rfind('/') + 1:])
+            elif item.startswith('data_segs_out:'):
+                flow_data['data_segs_out'] = int(item[item.rfind(':') + 1:])
+            elif item.startswith('rtt:'):
+                flow_data['rtt'] = (
+                    float(item[item.find(':') + 1:item.rfind('/')]) / 1000
+                )
+            elif item.startswith('unacked:'):
+                flow_data['unacked'] = int(item[item.find(':') + 1:])
+        debug('time_data for time %s port %d: %s' %
+              (time_secs, port, flow_data))
+        if not 'cwnd' in flow_data:
+            sys.stderr.write('unable to find cwnd in: %s' % (line))
+            #print('unable to find cwnd in: %s' % (line))
+            sys.exit()
+        time_data[port] = flow_data
+        # Move on to the next line:
+        line = f.readline()
+
+def log_retrans_rate(all_data):
+    """Log average retransmit rate for each flow and globally."""
+    outdir = os.environ['outdir']
+
+    last_data_segs_out = {}  # last data_segs_out per port
+    last_retrans =       {}  # last retransmitted packet count per port
+    retrans_rates = {}      # maps port number to retrans rate
+    for t in sorted(all_data.keys()):
+        time_data = all_data[t]
+        for port, flow_data in time_data.items():
+            debug('port %d flow_data %s' % (port, flow_data))
+            last_data_segs_out[port] = flow_data.get('data_segs_out', 0)
+            debug('port %d last_data_segs_out=%s' %
+                  (port, last_data_segs_out[port]))
+            last_retrans[port] = flow_data.get('retrans', 0)
+            debug('port %d last_retrans=' % last_retrans[port])
+
+    total_retrans = 0
+    total_data_segs_out = 0
+    for port in sorted(last_data_segs_out):
+        if last_data_segs_out[port] == 0:
+            sys.stderr.write('outdir=%s port %d: last_data_segs_out==0\n' %
+                             (outdir, port))
+            retrans = 0
+        else:
+            retrans = float(last_retrans[port]) / float(last_data_segs_out[port])
+        retrans_rates[port] = retrans
+        total_retrans += last_retrans[port]
+        total_data_segs_out += last_data_segs_out[port]
+    if total_data_segs_out == 0:
+        sys.stderr.write('outdir=%s total_data_segs_out==0\n' % (outdir))
+        total_retrans_rate = 0
+    else:
+        total_retrans_rate = float(total_retrans) / float(total_data_segs_out)
+
+    # Write average retx rate for each flow, in percent.
+    i = 0
+    for port, retrans_rate in retrans_rates.items():
+        filename = 'retrans.out.%d.txt' % (i)
+        f = open(os.path.join(outdir, filename), 'w')
+        f.write('%.5f\n' % (retrans_rate * 100.0))
+        f.close()
+        i += 1
+
+    # Write average retx rate across all flows, in percent.
+    filename = 'retrans.out.total.txt'
+    f = open(os.path.join(outdir, filename), 'w')
+    f.write('%.5f\n' % (total_retrans_rate * 100.0))
+    f.close()
+
+def log_rtt(all_data):
+    """Log median srtt for all srtt samples we took from periodic ss dumps."""
+    rtts = []
+    for t in sorted(all_data.keys()):
+        time_data = all_data[t]
+        for port, flow_data in time_data.items():
+            debug('port %d flow_data %s' % (port, flow_data))
+            if 'rtt' in flow_data:
+                rtt = flow_data['rtt']
+                rtts.append(rtt)
+
+    p50_rtt = median(rtts)
+    p50_rtt = p50_rtt * 1000.0   # convert to ms
+    # Write p50 srtt sample (in secs) we took across all flows.
+    outdir = os.environ['outdir']
+    filename = 'rtt_p50.out.total.txt'
+    f = open(os.path.join(outdir, filename), 'w')
+    f.write('%s\n' % p50_rtt)   # RTT in ms
+    f.close()
+
+def main():
+    """Main function to run everything."""
+    all_data = read_file()
+    log_retrans_rate(all_data)
+    log_rtt(all_data)
+    return 0
+
+if __name__ == '__main__':
+    sys.exit(main())
-- 
2.34.1

